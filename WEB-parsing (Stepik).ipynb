{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1778fa-b690-4fd6-b0ad-d45b857dd6d5",
   "metadata": {},
   "source": [
    "### Основные команды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f736d-403e-48a7-88b2-0f195346aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Шаг 1: Получаем HTML-код страницы\n",
    "url = 'https://parsinger.ru/4.3/4/index.html'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Шаг 2: Парсим HTML-код\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Шаг 3: Ищем все теги p\n",
    "p_tags = soup.find_all('p')\n",
    "\n",
    "# Шаг 4: Извлекаем значение атрибутов id и class\n",
    "total_id_sum = 0\n",
    "total_class_sum = 0\n",
    "for p in p_tags:\n",
    "    if len(p.text.replace(' ', '')) % 2 == 0: # стираем пробелы и проверяем длину строки на четность\n",
    "        total_id_sum += int(p.get('id'))\n",
    "        total_class_sum += int(p.get('class')[0])\n",
    "print(total_id_sum + total_class_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30978d-cbe5-40f9-a4f4-521b42ed9f91",
   "metadata": {},
   "source": [
    "### Все возможные поля в ответе response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296543d-acd9-4f73-a37e-38b43a237a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL для примеров\n",
    "url = \"https://httpbin.org/user-agent\"\n",
    "# Выполняем GET-запрос\n",
    "    response = requests.get(url)\n",
    "# status_code: HTTP-код статуса ответа.\n",
    "    print(\"HTTP-код статуса ответа:\", response.status_code)\n",
    "# text: Текстовое представление содержимого ответа.\n",
    "    print(\"Текстовое содержимое ответа:\", response.text)\n",
    "# content: Содержимое ответа в виде байтов.\n",
    "    print(\"Содержимое ответа в виде байтов:\", response.content)\n",
    "# json: Метод для десериализации JSON-ответа.\n",
    "    json_response = response.json()\n",
    "    print(\"Десериализованный JSON-ответ:\", json_response)\n",
    "# headers: Заголовки HTTP, возвращаемые сервером.\n",
    "    print(\"Заголовки HTTP:\", response.headers)\n",
    "# url: Исходный URL-адрес, на который был выполнен запрос.\n",
    "    print(\"Исходный URL-адрес запроса:\", response.url)\n",
    "# encoding: Кодировка ответа.\n",
    "    print(\"Кодировка ответа:\", response.encoding)\n",
    "# elapsed: Время, затраченное на выполнение запроса.\n",
    "    print(\"Время выполнения запроса:\", response.elapsed)\n",
    "# cookies: Куки, возвращаемые сервером.\n",
    "    print(\"Куки, возвращаемые сервером:\", response.cookies)\n",
    "# history: Список объектов Response, представляющих историю перенаправлений.\n",
    "    print(\"История перенаправлений:\", response.history)\n",
    "# ok: Логический атрибут, указывающий, был ли запрос успешным (коды 2xx).\n",
    "    print(\"Запрос успешен (коды 2xx):\", response.ok)\n",
    "# reason: Сообщение статуса HTTP (например, \"OK\", \"Not Found\").\n",
    "    print(\"Сообщение статуса HTTP:\", response.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb443874-1224-4ffd-bb45-4d7061e89369",
   "metadata": {},
   "source": [
    "### Передача параметров в URL params="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9c995-1fbb-4866-9458-68ca7218005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Базовый URL для поиска в онлайн-магазине\n",
    "base_url = 'https://example.com/search'\n",
    "\n",
    "# Параметры поиска: ищем ноутбуки с определенными характеристиками\n",
    "search_params = {\n",
    "    'query': 'note',  # Поисковый запрос\n",
    "    'brand': 'Dell',  # Бренд\n",
    "    'min_price': '50000',  # Минимальная цена\n",
    "    'max_price': '100000',  # Максимальная цена\n",
    "    'sort': 'price_asc'  # Сортировка по возрастанию цены\n",
    "}\n",
    "\n",
    "# Отправляем GET-запрос с параметрами\n",
    "response = requests.get(base_url, params=search_params)\n",
    "\n",
    "# Проверка успешности запроса\n",
    "if response.status_code == 200:\n",
    "    # Парсим HTML-страницу с использованием BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Находим все элементы, соответствующие карточкам товаров (здесь это примерный CSS-селектор)\n",
    "    product_cards = soup.select('.product-card')\n",
    "\n",
    "    for card in product_cards:\n",
    "        # Извлекаем информацию из карточки товара (название и цена)\n",
    "        product_name = card.select_one('.product-name').text\n",
    "        product_price = card.select_one('.product-price').text\n",
    "\n",
    "        print(f'Название товара: {product_name}')\n",
    "        print(f'Цена товара: {product_price}')\n",
    "        print('---')\n",
    "else:\n",
    "    print(f'Не удалось выполнить запрос. Код ошибки: {response.status_code}')\n",
    "    print(response.url)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28d84f1a-f4aa-4799-b2ce-0bf9657c2278",
   "metadata": {},
   "source": [
    "Cформированная ссылка куда будет отправлен запрос будет выглядеть так: \n",
    "https://example.com/search?query=note&brand=Dell&min_price=50000&max_price=100000&sort=price_asc\n",
    "Примеры применения параметров тут:\n",
    "https://stepik.org/lesson/691440/step/5?unit=690987"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bc620-de16-4029-979a-14a8cee068ee",
   "metadata": {},
   "source": [
    "### Скачиваем файл по прямой ссылке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa01f8-2b8e-4de7-9b6f-693b5c5a2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "скачиваем файл по прямой ссылке, делим его на куски по 100 000 байт чтобы ускорить процесс и не грузить оперативную память\n",
    "stream=true поддерживаем соединение открытым\n",
    "wb - режим бинарных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa8bbe-4c83-462c-a204-de58f88276e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем файл кусочками\n",
    "import requests\n",
    "response = requests.get(url='https://parsinger.ru/video_downloads/videoplayback.mp4', stream=True)\n",
    "with open('file.mp4', 'wb') as video:\n",
    "    for piece in response.iter_content(chunk_size=100000):\n",
    "        video.write(piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df8a15-1430-4162-99c7-ba66edf1c2eb",
   "metadata": {},
   "source": [
    "### Скачиваем с сайта все изображения (код из ChatGPT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fe7ab-4df2-4456-9323-254c31b7398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# URL сайта\n",
    "url = \"https://parsinger.ru/img_download/index.html\"\n",
    "# Папка для сохранения изображений\n",
    "download_directory = \"images_parsing_lesson\"\n",
    "# Создаем папку для сохранения изображений, если она не существует\n",
    "if not os.path.exists(download_directory):\n",
    "    os.makedirs(download_directory)\n",
    "\n",
    "# Функция для получения всех изображений на странице\n",
    "def get_all_images(page_url):\n",
    "    try:\n",
    "        response = requests.get(page_url)\n",
    "        response.raise_for_status()  # Проверяем успешность запроса\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        image_tags = soup.find_all(\"img\")\n",
    "        image_urls = [urljoin(page_url, img[\"src\"]) for img in image_tags]\n",
    "        return image_urls\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ошибка при получении изображений: {e}\")\n",
    "        return []\n",
    "\n",
    "# Функция для скачивания изображений\n",
    "def download_images(image_urls, download_folder):\n",
    "    for image_url in image_urls:\n",
    "        try:\n",
    "            filename = os.path.join(download_folder, os.path.basename(urlparse(image_url).path))\n",
    "            urlretrieve(image_url, filename)\n",
    "            print(f\"Скачано: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при скачивании изображения {image_url}: {e}\")\n",
    "\n",
    "# Получаем все изображения на странице\n",
    "all_images = get_all_images(url)\n",
    "# Скачиваем изображения\n",
    "download_images(all_images, download_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c2b8f-7c7f-4714-92cf-921f318f4298",
   "metadata": {},
   "source": [
    "### Используем список Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd63e3f-95f7-42c5-aac3-74cd4d9371eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies_list = [\n",
    "    {'http': 'http://10.10.36.159:8000', 'https': 'https://10.10.36.159:8000'},\n",
    "    {'http': 'http://10.10.51.205:8000', 'https': 'https://10.10.51.205:8000'},\n",
    "    {'http': 'http://10.10.79.216:8000', 'https': 'https://10.10.79.216:8000'}]\n",
    "proxy_pool = cycle(proxies_list)\n",
    "url = \"http://example.org\"\n",
    "\n",
    "# Создание сессии\n",
    "session = requests.Session()\n",
    "for i in range(1, 6):  # Попробуем сделать 5 запросов\n",
    "    proxy = next(proxy_pool)\n",
    "    session.proxies.update(proxy)  # Обновление прокси для сессии\n",
    "    try:\n",
    "        response = session.get(url, timeout=5)  # Используем сессию для выполнения запроса\n",
    "        print(f\"Request {i}: Success!\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request {i}: Failed, switching proxy. {proxy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5dc313-32a4-4fc2-82e6-c769191eb610",
   "metadata": {},
   "source": [
    "### Работа с html оффлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d48c42-5750-44fa-b583-bd245d640c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# анализ скаченного файла html оффлайн\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "with open('index.html', 'r', encoding='utf-8') as file:\n",
    "    soup2 = BeautifulSoup(file, 'lxml')\n",
    "    print(\"Анализ файла с использованием менеджера контекста:\\n\", soup2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d0844-6ac8-4ac3-90be-c92e245e0a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7800e2-4d15-4053-8cbe-4f4f7492955e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e80d26-6293-4299-ada4-5641dd2ee3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно попробовать вместо get поставить head, но вроде быстрее не стало\n",
    "# вычисляем сумму статусов ответов от 200 сайтов\n",
    "url = 'https://parsinger.ru/3.3/2/1.html'\n",
    "summa = 0\n",
    "with requests.Session() as s:\n",
    "    for i in range(1, 201):\n",
    "        url = 'https://parsinger.ru/3.3/2/'+str(i)+'.html'\n",
    "        response = s.get(url)\n",
    "        summa+= response.status_code\n",
    "print(\"Сумма статусов:\", summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e6ad3-cac1-4ba5-8725-8c9f2de2f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = f'http://parsinger.ru/task/1/{x}.html'\n",
    "# ищем первый рабочий сайт из 200\n",
    "with requests.Session() as s:\n",
    "    for i in range(1, 201):\n",
    "        url = 'https://parsinger.ru/3.3/1/'+str(i)+'.html'\n",
    "        response = s.get(url)\n",
    "        if response.status_code == 200:\n",
    "            print(url)\n",
    "            print(response.text)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed81ca-ec35-461c-8f59-d67f77770a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем самое большое изображение по объему\n",
    "name_img = ['1663231240183817644.jpg', '1663231245165469794.jpg', '1663231252148267596.jpg', '16632460271311817.jpg', '1663260860165832550.jpg',\n",
    " '1663260862112644405.jpg', '1663260864114071369.jpg', '1663260869127473152.jpg', '1663260874115452216.jpg', '1663260877136512181.jpg',\n",
    " '1663260878140464277.jpg', '1663267600193799276.jpg', '1663267613117130673.jpg', '1663267619197170483.jpg', '1663267626154597739.jpg',\n",
    " '1663267648135114690.jpg', '166326765416196421.jpg', '1663267662118079649.jpg', '1663267668165066872.jpg', '1663267878176341940.jpg',\n",
    " '166326990115068678.jpg', '1663269922185881885.jpg', '1663269927127433209.jpg', '1663269942143420441.jpg', '1663269946174943071.jpg',\n",
    " '1663269964195277579.jpg', '1663269970148058649.jpg', '1663269974197750992.jpg', '166326997917397750.jpg', '1663270039138442380.jpg',\n",
    " '1663388012194470737.jpg', '166342371029995280.jpg', '1663423712288242036.jpg', '1663423715255612089.jpg', '1663423720221155166.jpg',\n",
    " '1663423722211139858.jpg', '1663423724211218483.jpg', '1663423728215479371.jpg', '1663423729298828299.jpg', '1663423732225964403.jpg',\n",
    " '1663424198111663025.jpg', '1663424199157537861.jpg', '1663424200184778832.jpg', '166342420214123494.jpg', '166342420317539591.jpg',\n",
    " '1663424204161674559.jpg', '1663424206188873432.jpg', '166342420813193185.jpg', '1663424209187179962.jpg', '1663424212162573102.jpg']\n",
    "url = 'https://parsinger.ru/3.3/3/img/'\n",
    "max_size = 0.0\n",
    "max = name_img[0]\n",
    "with requests.Session() as s:\n",
    "    for img in name_img:\n",
    "        url = 'https://parsinger.ru/3.3/3/img/' + img\n",
    "        response = s.get(url)\n",
    "        if int(response.headers.get('Content-Length')) > max_size:\n",
    "            max = img\n",
    "            max_size = int(response.headers.get('Content-Length'))\n",
    "print(max[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73d32d-44b7-4a35-8576-fdf28f18632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://parsinger.ru/3.3/4/1.html'\n",
    "first = 1\n",
    "last = 1\n",
    "with requests.Session() as s:\n",
    "    for i in range(1, 101):\n",
    "        url = 'https://parsinger.ru/3.3/4/' + str(i) + '.html'\n",
    "        response = s.get(url)\n",
    "        if response.status_code == 200:\n",
    "            first = i\n",
    "            break\n",
    "    for j in range(i, 101):\n",
    "        url = 'https://parsinger.ru/3.3/4/' + str(j) + '.html'\n",
    "        response = s.get(url)\n",
    "        if response.status_code == 200:\n",
    "            last = j\n",
    "print(f\"Первая доступная страница: {first}.html\")\n",
    "print(f\"Последняя доступная страница: {last}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaf12a-91b0-40a7-bc0e-11bde2f9a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исправляем нечитаемую кодировку\n",
    "url = 'https://parsinger.ru/3.4/2/index.html'\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "print(\"Содержимое ответа:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaeaa7f-4a2f-4d7a-8301-7160262059c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://parsinger.ru/img_download/img/ready/1.png'\n",
    "with requests.Session() as s:\n",
    "    for i in range(1, 6):\n",
    "        url = 'https://parsinger.ru/img_download/img/ready/' + str(i) + '.png'\n",
    "        response = s.get(url)\n",
    "        with open('image'+str(i)+'.jpeg', 'wb') as file:\n",
    "            file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82378ba4-cd34-440e-be6a-6a697a077cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url='https://parsinger.ru/3.4/1/json_weather.json')\n",
    "weather = response.json()\n",
    "min_temperature_date = min(weather, key=lambda x: int(x['Температура воздуха'][:-2]))['Дата']\n",
    "# список weather состоит из словарей, сперва мы находим такой элемент списка, у которого минимальное значение по ключу [Температура],\n",
    "# а потом из полученного элемента словаря извлекаем значение по ключу [Дата]\n",
    "#min_temp = min(weather, key=lambda x: x['Температура воздуха'])\n",
    "print(min_temperature_date)\n",
    "print(type(weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9cdbff-4232-4181-9a30-4c4a003dfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url='https://parsinger.ru/3.4/3/dialog.json')\n",
    "chat = response.json()\n",
    "\n",
    "def dict_to_list(d):\n",
    "    result = []\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            result.append({key: dict_to_list(value)})\n",
    "        else:\n",
    "            result.append({key: value})\n",
    "    return result\n",
    "\n",
    "chat_list = dict_to_list(chat)\n",
    "print(len(chat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056d7c8-56c6-4946-a188-dd7c85fe9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Пример входного словаря\n",
    "tree_dict = {\n",
    "    'a': {\n",
    "        'b': {\n",
    "            'c': 1,\n",
    "            'd': 2\n",
    "        },\n",
    "        'e': 3\n",
    "    },\n",
    "    'f': 4\n",
    "}\n",
    "\n",
    "# Преобразование словаря в список с одним уровнем вложенности\n",
    "flat_list = flatten_dict(tree_dict)\n",
    "print(flat_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6260aa-da6c-4293-9976-1917a658f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Пример HTML-строки\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ru\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Пример карточки товара</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"card\">\n",
    "        <img src=\"image.jpg\" alt=\"Пример изображения товара\">\n",
    "        <h2 class=\"card-title\"> iPhone 15 </h2>\n",
    "        <p class=\"card-description\">Аппаратной основой Apple iPhone 15 Pro Max стал 3-нанометровый чипсет A17 Pro с 6-ядерным GPU и поддержкой трассировки лучей. </p>\n",
    "        <p class=\"card-price\">999 999 руб.</p>\n",
    "        <a href=\"https://example.com/product-link\" class=\"card-link\">Подробнее</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# Создание объекта BeautifulSoup\n",
    "soup = BeautifulSoup(html_string, 'html.parser')\n",
    "# Использование .text для извлечения всего текста из div\n",
    "div_text = soup.find('div').text\n",
    "print(div_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc1cd9-29c2-4bfa-ba8f-a9256f2a9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ru\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"cards\">\n",
    "        <!-- Карточка товара 1 -->\n",
    "        <div class=\"card\">\n",
    "            <img src=\"parsing.png\" alt=\"WEB Парсинг на Python\">\n",
    "            <h2 class=\"card-title\">WEB Парсинг на Python</h2>\n",
    "            <p class=\"card-articul\">Артикул: 104774</p>\n",
    "            <p class=\"card-stock\">Наличие: 5 шт.</p>\n",
    "            <p class=\"card-price\">3500 руб.</p>\n",
    "            <a href=\"https://stepik.org/a/104774\" class=\"card-button\">Купить</a>\n",
    "        </div>\n",
    "        <!-- Карточка товара 2 -->\n",
    "        <div class=\"card\">\n",
    "            <img src=\"async.png\" alt=\"Асинхронный Python\">\n",
    "            <h2 class=\"card-title\">Асинхронный Python</h2>\n",
    "            <p class=\"card-articul\">Артикул: 170777</p>\n",
    "            <p class=\"card-stock\">Наличие: 10 шт.</p>\n",
    "            <p class=\"card-price\">3500 руб.</p>\n",
    "            <a href=\"https://stepik.org/a/170777\" class=\"card-button\">Купить</a>\n",
    "        </div>\n",
    "        <!-- Карточка товара 3 -->\n",
    "        <div class=\"card\">\n",
    "            <img src=\"selenium.PNG\" alt=\"Selenium Python\">\n",
    "            <h2 class=\"card-title\">Selenium Python</h2>\n",
    "            <p class=\"card-articul\">Артикул: 119495</p>\n",
    "            <p class=\"card-stock\">Наличие: 5 шт.</p>\n",
    "            <p class=\"card-price\">1250 руб.</p>\n",
    "            <a href=\"https://stepik.org/a/119495\" class=\"card-button\">Купить</a>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "def main (html_string):\n",
    "    # Инициализация объекта BeautifulSoup\n",
    "    soup = BeautifulSoup(html_string, 'html.parser')\n",
    "\n",
    "    # Поиск всех элементов с классом 'card-articul'\n",
    "    articuls = soup.find_all(class_='card-articul')\n",
    "    for art in articuls:\n",
    "        print(int(art.text[-6:]))\n",
    "        \n",
    "    # Извлечение числовых значений артикулов и их суммирование\n",
    "    sum_articuls = sum([int(art.text[-6:]) for art in articuls])\n",
    "\n",
    "    print(f\"Сумма артикулов: {sum_articuls}\")  # Вывод результата\n",
    "main(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9dbe4-0617-4a5a-b68a-93e12944c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ru\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"card\">\n",
    "    <h2>Товар 1</h2>\n",
    "    <img src=\"parsing.png\" alt=\"779966\">\n",
    "    <p>Цена: 1000 руб.</p>\n",
    "    <p>Описание: Отличный товар, изготовлен из качественных материалов.</p>\n",
    "    <p>Технические характеристики: Размеры: 10x10x10 см, Вес: 1 кг.</p>\n",
    "    <p>Доступные размеры: S, M, L</p>\n",
    "    <p>Отзывы: 5 звезд</p>\n",
    "    <p>Наличие на складе: В наличии</p>\n",
    "    <p>Информация о доставке: Бесплатно при заказе от 3000 руб.</p>\n",
    "    <a href=\"https://stepik.org/a/104774\" class=\"btn\">Купить</a>\n",
    "</div>\n",
    "<div class=\"card\">\n",
    "    <h2>Товар 2</h2>\n",
    "    <img src=\"async.png\" alt=\"331155\">\n",
    "    <p>Цена: 1500 руб.</p>\n",
    "    <p>Описание: Превосходный товар, подходит для повседневного использования.</p>\n",
    "    <p>Технические характеристики: Размеры: 15x15x15 см, Вес: 1.5 кг.</p>\n",
    "    <p>Доступные размеры: M, L, XL</p>\n",
    "    <p>Отзывы: 4.5 звезд</p>\n",
    "    <p>Наличие на складе: В наличии</p>\n",
    "    <p>Информация о доставке: Бесплатно при заказе от 5000 руб.</p>\n",
    "    <a href=\"https://stepik.org/a/170777\" class=\"btn\">Купить</a>\n",
    "</div>\n",
    "<div class=\"card\">\n",
    "    <h2>Товар 3</h2>\n",
    "    <img src=\"parsing.png\" alt=\"558877\">\n",
    "    <p>Цена: 2000 руб.</p>\n",
    "    <p>Описание: Удобный товар для дома и офиса.</p>\n",
    "    <p>Технические характеристики: Размеры: 12x12x12 см, Вес: 1.2 кг.</p>\n",
    "    <p>Доступные размеры: S, M</p>\n",
    "    <p>Отзывы: 4.7 звезд</p>\n",
    "    <p>Наличие на складе: В наличии</p>\n",
    "    <p>Информация о доставке: Бесплатно при заказе от 3500 руб.</p>\n",
    "    <a href=\"https://stepik.org/a/104774\" class=\"btn\">Купить</a>\n",
    "</div>\n",
    "<div class=\"card\">\n",
    "    <h2>Товар 4</h2>\n",
    "    <img src=\"async.png\" alt=\"449933\">\n",
    "    <p>Цена: 2500 руб.</p>\n",
    "    <p>Описание: Стильный и практичный товар.</p>\n",
    "    <p>Технические характеристики: Размеры: 14x14x14 см, Вес: 1.4 кг.</p>\n",
    "    <p>Доступные размеры: L, XL</p>\n",
    "    <p>Отзывы: 4.8 звезд</p>\n",
    "    <p>Наличие на складе: В наличии</p>\n",
    "    <p>Информация о доставке: Бесплатно при заказе от 4000 руб.</p>\n",
    "    <a href=\"https://stepik.org/a/170777\" class=\"btn\">Купить</a>\n",
    "</div>\n",
    "<div class=\"card\">\n",
    "    <h2>Товар 5</h2>\n",
    "    <img src=\"parsing.png\" alt=\"667711\">\n",
    "    <p>Цена: 2700 руб.</p>\n",
    "    <p>Описание: Идеальный товар для повседневного использования.</p>\n",
    "    <p>Технические характеристики: Размеры: 13x13x13 см, Вес: 1.3 кг.</p>\n",
    "    <p>Доступные размеры: M, L, XL</p>\n",
    "    <p>Отзывы: 4.9 звезд</p>\n",
    "    <p>Наличие на складе: В наличии</p>\n",
    "    <p>Информация о доставке: Бесплатно при заказе от 4500 руб.</p>\n",
    "    <a href=\"https://stepik.org/a/104774\" class=\"btn\">Купить</a>\n",
    "</div>\n",
    "<div class=\"card\">\n",
    "    <h2>Товар 6</h2>\n",
    "    <img src=\"async.png\" alt=\"334455\">\n",
    "    <p>Цена: 3000 руб.</p>\n",
    "    <p>Описание: Прочный и надежный товар.</p>\n",
    "    <p>Технические характеристики: Размеры: 16x16x16 см, Вес: 1.6 кг.</p>\n",
    "    <p>Доступные размеры: S, M</p>\n",
    "    <p>Отзывы: 5 звезд</p>\n",
    "    <p>Наличие на складе: В наличии</p>\n",
    "    <p>Информация о доставке: Бесплатно при заказе от 5000 руб.</p>\n",
    "    <a href=\"https://stepik.org/a/170777\" class=\"btn\">Купить</a>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "def main(html_string):\n",
    "    # Инициализация объекта BeautifulSoup\n",
    "    soup = BeautifulSoup(html_string, 'html.parser')\n",
    "\n",
    "    # Находим все теги img\n",
    "    img_tags = soup.find_all('img')\n",
    "    \n",
    "    # Извлекаем значения атрибута alt и суммируем их\n",
    "    total_sum = sum([int(img.get('alt')) for img in img_tags])\n",
    "    print(f\"Сумма всех значений в атрибуте alt тега img: {total_sum}\")\n",
    "\n",
    "main(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209ee21-c3be-48f2-8b44-13faa7c5d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://parsinger.ru/4.1/1/index4.html'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "prices = soup.find_all('p', attrs = {'class' : 'price product_price'})\n",
    "count = 0\n",
    "for price in prices:\n",
    "    count += int(price.text.replace(' ', '')[:-3]) # убрали пробелы и откинула руб\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0624e76-31b8-4c3c-afee-210c2ffda01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://parsinger.ru/4.1/1/index4.html'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "tags_li = soup.find_all('li')\n",
    "for tag in tags_li:\n",
    "    print(tag.get('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e97ee3-6d4f-4314-a6c4-c443c4beb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://parsinger.ru/4.1/1/index6.html'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "sibling = soup.find(id= 'section3').find('p').next_sibling.strip()\n",
    "abzac = soup.find(id= 'section3') # для понимания что мы ищем\n",
    "print(abzac)\n",
    "print(sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ada9d-1516-4017-bdc4-60addb231fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://parsinger.ru/4.1/1/index5.html'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "emails = [mail.find('strong').next_sibling.strip() for mail in soup.find_all('div', class_= 'email_field')]\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5bfab-95cc-4450-9874-b08abd74fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "html ='''<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Онлайн Магазин Книг</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"book-card\">\n",
    "        <img src=\"1.png\" alt=\"Обложка книги 1\" class=\"book-cover book-cover_hard\">\n",
    "        <h2 class=\"book pages\">Название Книги 1</h2>\n",
    "        <p class=\"book-author\">Автор: Автор 1</p>\n",
    "        <p class=\"book-isbn\">ISBN: 978-1234567890</p>\n",
    "        <p class=\"book-cover-type\">Обложка: Твердая</p>\n",
    "        <p class=\"count price\">Цена: $20.00</p>\n",
    "        <p class=\"book-format\">Формат: Мягкая обложка</p>\n",
    "        <p class=\"count pages\">Количество страниц: 300</p>\n",
    "        <p class=\"count stock\">Количество на складе: 75</p>\n",
    "        <p class=\"book-publisher\">Издательство: Издательство 1</p>\n",
    "        <p class=\"book-publication-date\">Дата публикации: 01.01.2023</p>\n",
    "        <p class=\"count rating\">Рейтинг: 4.5</p>\n",
    "        <p class=\"book-genre\">Жанр: Роман</p>\n",
    "        <p class=\"book-language\">Язык: Английский</p>\n",
    "        <p class=\"book-availability\">Доступность: В наличии</p>\n",
    "        <p class=\"book-description\">Описание: Краткое описание книги 1.</p>\n",
    "        <button class=\"book-purchase-btn\">Добавить в корзину</button>\n",
    "    </div>\n",
    "    <div class=\"book-card\">\n",
    "        <img src=\"2.png\" alt=\"Обложка книги 2\" class=\"book-cover book-cover_hard\">\n",
    "        <h2 class=\"book pages\">Название Книги 2</h2>\n",
    "        <p class=\"book-author\">Автор: Автор 2</p>\n",
    "        <p class=\"book-isbn\">ISBN: 978-9876543210</p>\n",
    "        <p class=\"book-cover-type\">Обложка: Мягкая</p>\n",
    "        <p class=\"count price\">Цена: $18.50</p>\n",
    "        <p class=\"book-format\">Формат: Электронная версия (e-book)</p>\n",
    "        <p class=\"count pages\">Количество страниц: 250</p>\n",
    "        <p class=\"count stock\">Количество на складе: 119</p>\n",
    "        <p class=\"book-publisher\">Издательство: Издательство 3</p>\n",
    "        <p class=\"book-publication-date\">Дата публикации: 20.03.2023</p>\n",
    "        <p class=\"count rating\">Рейтинг: 4.7</p>\n",
    "        <p class=\"book-genre\">Жанр: Детская литература</p>\n",
    "        <p class=\"book-language\">Язык: Французский</p>\n",
    "        <p class=\"book-availability\">Доступность: В наличии</p>\n",
    "        <p class=\"book-description\">Описание: Краткое описание книги 2.</p>\n",
    "         <button class=\"book-purchase-btn\">Добавить в корзину</button>\n",
    "    </div>\n",
    "    <div class=\"book-card\">\n",
    "        <img src=\"3.png\" alt=\"Обложка книги 3\" class=\"book-cover book-cover_hard\">\n",
    "        <h2 class=\"book pages\">Название Книги 3</h2>\n",
    "        <p class=\"book-author\">Автор: Автор 3</p>\n",
    "        <p class=\"book-isbn\">ISBN: 978-0987654321</p>\n",
    "        <p class=\"book-cover-type\">Обложка: Твердая</p>\n",
    "        <p class=\"count price\">Цена: $25.00</p>\n",
    "        <p class=\"book-format\">Формат: Мягкая обложка</p>\n",
    "        <p class=\"count pages\">Количество страниц: 400</p>\n",
    "        <p class=\"count stock\">Количество на складе: 216</p>\n",
    "        <p class=\"book-publisher\">Издательство: Издательство 2</p>\n",
    "        <p class=\"book-publication-date\">Дата публикации: 15.02.2023</p>\n",
    "        <p class=\"count rating\">Рейтинг: 4.8</p>\n",
    "        <p class=\"book-genre\">Жанр: Фантастика</p>\n",
    "        <p class=\"book-language\">Язык: Русский</p>\n",
    "        <p class=\"book-availability\">Доступность: В наличии</p>\n",
    "        <p class=\"book-description\">Описание: Краткое описание книги 3.</p>\n",
    "        <button class=\"book-purchase-btn\">Добавить в корзину</button>\n",
    "    </div>\n",
    "    <div class=\"book-card\">\n",
    "        <img src=\"4.png\" alt=\"Обложка книги 4\" class=\"book-cover book-cover_hard\">\n",
    "        <h2 class=\"book pages\">Название Книги 4</h2>\n",
    "        <p class=\"book-author\">Автор: Автор 4</p>\n",
    "        <p class=\"book-isbn\">ISBN: 978-5432109876</p>\n",
    "        <p class=\"book-cover-type\">Обложка: Твердая</p>\n",
    "        <p class=\"count price\">Цена: $22.00</p>\n",
    "        <p class=\"book-format\">Формат: Мягкая обложка</p>\n",
    "        <p class=\"count pages\">Количество страниц: 350</p>\n",
    "        <p class=\"count stock\">Количество на складе: 17</p>\n",
    "        <p class=\"book-publisher\">Издательство: Издательство 4</p>\n",
    "        <p class=\"book-publication-date\">Дата публикации: 10.04.2023</p>\n",
    "        <p class=\"count rating\">Рейтинг: 4.9</p>\n",
    "        <p class=\"book-genre\">Жанр: Детектив</p>\n",
    "        <p class=\"book-language\">Язык: Английский</p>\n",
    "        <p class=\"book-availability\">Доступность: В наличии</p>\n",
    "        <p class=\"book-description\">Описание: Краткое описание книги 4.</p>\n",
    "        <button class=\"book-purchase-btn\">Добавить в корзину</button>\n",
    "    </div>\n",
    "    <div class=\"book-card\">\n",
    "        <img src=\"5.png\" alt=\"Обложка книги 5\" class=\"book-cover book-cover_hard\">\n",
    "        <h2 class=\"book pages\">Название Книги 5</h2>\n",
    "        <p class=\"book-author\">Автор: Автор 5</p>\n",
    "        <p class=\"book-isbn\">ISBN: 978-8765432109</p>\n",
    "        <p class=\"book-cover-type\">Обложка: Мягкая</p>\n",
    "        <p class=\"count price\">Цена: $19.50</p>\n",
    "        <p class=\"book-format\">Формат: Мягкая обложка</p>\n",
    "        <p class=\"count pages\">Количество страниц: 280</p>\n",
    "        <p class=\"count stock\">Количество на складе: 63</p>\n",
    "        <p class=\"book-publisher\">Издательство: Издательство 5</p>\n",
    "        <p class=\"book-publication-date\">Дата публикации: 05.05.2023</p>\n",
    "        <p class=\"count rating\">Рейтинг: 4.6</p>\n",
    "        <p class=\"book-genre\">Жанр: Фэнтези</p>\n",
    "        <p class=\"book-language\">Язык: Испанский</p>\n",
    "        <p class=\"book-availability\">Доступность: В наличии</p>\n",
    "        <p class=\"book-description\">Описание: Краткое описание книги 5.</p>\n",
    "        <button class=\"book-purchase-btn\">Добавить в корзину</button>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "def calculate_total_price(html: str) -> float:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    price_list = [float(price.text[7:]) for price in soup.find_all('p', class_= \"count price\")]\n",
    "    amount_list = [float(q.text[21:]) for q in soup.find_all('p', class_= \"count stock\")]\n",
    "    price_amount = list(zip(price_list, amount_list))\n",
    "    calculate_total_price = sum(a*q for a, q in price_amount)\n",
    "    return calculate_total_price\n",
    "\n",
    "print(f\"Общая стоимость в случае продажи всех товаров: ${calculate_total_price(html):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3eae32-8b92-43db-b546-09d2b9d23606",
   "metadata": {},
   "source": [
    "#### Находим на сайте поля с стоимостью и количеством, перемножаем, узнаем суммарную стоимость всех позиций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec3a8e-5a99-4e87-8bd1-08744d2f7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тоже самое, но короче\n",
    "calculate_total_price = sum(float(price.text[7:]) * float(q.text[21:])\n",
    "    for price, q in zip(soup.find_all('p', class_=\"count price\"), soup.find_all('p', class_=\"count stock\")))\n",
    "print(calculate_total_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df52b980-9e97-4ad8-a0ca-664d1b80d208",
   "metadata": {},
   "source": [
    "#### Сравниваем время выполнения find_all для 1 и 2 запросов к сайту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367985c-6f37-4a16-ab66-9cf9f80ba773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import timeit\n",
    "\n",
    "url = 'https://parsinger.ru/4.3/5/index.html'\n",
    "response = requests.get(url)\n",
    "response.encoding= 'utf-8' # Исправление ошибки кодировки\n",
    "response.raise_for_status()  # Проверка, что запрос был успешным\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Код с двумя вызовами find_all\n",
    "code_two_calls = '''\n",
    "prices = [float(price.text[7:]) for price in soup.find_all('p', class_=\"count price\")]\n",
    "amounts = [float(amount.text[21:]) for amount in soup.find_all('p', class_=\"count stock\")]\n",
    "calculate_total_price = sum(p * a for p, a in zip(prices, amounts))\n",
    "'''\n",
    "# Код с одним вызовом find_all и разделением элементов\n",
    "code_one_call = '''\n",
    "elements = soup.find_all('p', class_=[\"count price\", \"count stock\"])\n",
    "prices = [float(el.text[12:]) for el in elements if \"price\" in el['class']]\n",
    "amounts = [float(el.text[21:]) for el in elements if \"stock\" in el['class']]\n",
    "calculate_total_price = sum(p * a for p, a in zip(prices, amounts))\n",
    "'''\n",
    "# Измерение времени выполнения\n",
    "time_two_calls = timeit.timeit(code_two_calls, globals=globals(), number=1000)\n",
    "time_one_call = timeit.timeit(code_one_call, globals=globals(), number=1000)\n",
    "\n",
    "print(f'Время выполнения с двумя вызовами find_all: {time_two_calls:.6f} секунд')\n",
    "print(f'Время выполнения с одним вызовом find_all: {time_one_call:.6f} секунд')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff85b2-0ad1-4462-b687-83ac4d29f602",
   "metadata": {},
   "source": [
    "#### Находоим на странице цены на все товары и складываем общую стоимость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10673e38-f84f-4dd2-b0e7-9f755fe1b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://parsinger.ru/html/index1_page_1.html'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "prices = sum(int(p.text[:-4]) for p in soup.find_all('p', class_= 'price'))\n",
    "print(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7017e3-d95a-481b-ae45-51ffb6e8009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://parsinger.ru/html/hdd/4/4_1.html'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "old_price = int(soup.find(id = 'old_price').text[:-4])\n",
    "new_price = int(soup.find(id = 'price').text[:-4])\n",
    "discount = (old_price - new_price)*100/old_price\n",
    "print(f\"{discount:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1591a0-7eb7-4a7a-ac01-c3c906e665ee",
   "metadata": {},
   "source": [
    "#### с 4 страниц сайта собираем названия товаров и складываем в двумерный список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9deac4-910c-4e82-bf12-19a5ed0469c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://parsinger.ru/html/index3_page_'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "names_table = []\n",
    "for i in range(1, 5):\n",
    "    site = url + str(i) + '.html'\n",
    "    response = requests.get(site)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    names_page = [name.text for name in soup.find_all('a', class_= 'name_item')]\n",
    "    names_table.append(names_page)\n",
    "print(names_table)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af177588-0889-4a0f-9369-a9ebce96512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://parsinger.ru/html/mouse/3/3_'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "art_sum = 0\n",
    "for i in range(1, 33):\n",
    "    site = url + str(i) + '.html'\n",
    "    response = requests.get(site)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    art_sum+= int(soup.find('p', class_= 'article').text[9:])\n",
    "print(art_sum)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca83a3-b5a9-4cba-b0dc-49d12057a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url0 = 'https://parsinger.ru/html/'\n",
    "#https://parsinger.ru/html/watch/1/1_1.html\n",
    "#https://parsinger.ru/html/mobile/2/2_1.html\n",
    "#https://parsinger.ru/html/mouse/3/3_1.html\n",
    "#https://parsinger.ru/html/hdd/4/4_1.html\n",
    "#https://parsinger.ru/html/headphones/5/5_1.html\n",
    "\n",
    "page_names = ['watch/1/1_', 'mobile/2/2_', 'mouse/3/3_', 'hdd/4/4_', 'headphones/5/5_']\n",
    "amount_on_page = [33, 33, 33, 33, 33]\n",
    "summa = 0\n",
    "for i in range(5):\n",
    "    for j in range(1, amount_on_page[i]):\n",
    "        site = url0 + page_names[i] + str(j) + '.html'\n",
    "        response = requests.get(site)\n",
    "        html_content = response.content\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        price = int(soup.find(id = 'price').text[:-4])\n",
    "        amount = int(soup.find(id = 'in_stock').text[11:])\n",
    "        summa+= price*amount\n",
    "print(summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fd89c-c651-4c60-85f5-2d8292984c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://stepik-parsing.ru/html/index1_page_1.html'\n",
    "response = requests.get(url=url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "pagen = int(soup.find('div', 'pagen').find_all('a')[-1].text)\n",
    "category = [f\"http://stepik-parsing.ru/html/{x['href']}\" for x in soup.find('div', 'nav_menu').find_all('a')]\n",
    "\n",
    "results = []\n",
    "for x in range(1, len(category)+1):\n",
    "    for i in range(1, pagen+1):\n",
    "        url = f'http://stepik-parsing.ru/html/index{x}_page_{i}.html'\n",
    "        response = requests.get(url=url)\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        name = [x.text.strip() for x in soup.find_all('a', 'name_item')]\n",
    "        link = [f\"http://stepik-parsing.ru/html/{x['href'].strip()}\" for x in soup.find_all('a', class_='name_item')]\n",
    "        result = [int(x.text.strip().split()[0]) for x in soup.find_all('p', 'price')]\n",
    "\n",
    "        for li, res in zip(link, result):\n",
    "            response = requests.get(url=li)\n",
    "            response.encoding = 'utf-8'\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            count = int(soup.find('span', id='in_stock').string.split(':')[1])\n",
    "            results.append(res * count)\n",
    "print(sum(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3430b0c-329f-463d-b9a9-d30cbe18f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://cbr.ru/Queries/AjaxDataSource/112805?DT=&val_id=R01239&_=1669744293513'\n",
    "response_euro = requests.get(url=url).json()\n",
    "#headers = {'user-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:106.0) Gecko/20100101 Firefox/106.0',\n",
    "#           'X-Requested-With': 'XMLHttpRequest', }\n",
    "#url = 'https://cbr.ru/Queries/AjaxDataSource/112805'\n",
    "data_dollar = {\n",
    "    'DT': '',\n",
    "    'val_id': 'R01235',\n",
    "    '_': '1667219511852'}\n",
    "data_euro = {\n",
    "    'DT': '',\n",
    "    'val_id': 'R01239',\n",
    "    '_': '1667219511853'}\n",
    "#response_dollar = requests.get(url=url, headers=headers, params=data_dollar).json()[-1]\n",
    "#response_euro = requests.get(url=url, headers=headers, params=data_euro).json()[-1]\n",
    "\n",
    "#print(f'Дата: {response_dollar[\"data\"][:10]}')\n",
    "#print(f'Курс USD: {response_dollar[\"curs\"]} рублей')\n",
    "print(f'Курс EUR: {response_euro[\"curs\"]} рублей')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57440e52-80c1-4edd-ad70-b98dc83387cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_usd = 'https://cbr.ru/cursonweek/?DT=&val_id=R01235&_=1692528097005'\n",
    "url_eur = 'https://cbr.ru/cursonweek/?DT=&val_id=R01239&_=1692528097006'\n",
    "url_cny = 'https://cbr.ru/cursonweek/?DT=&val_id=R01375&_=1692528097007'\n",
    "\n",
    "urls_list = [url_usd, url_eur, url_cny]\n",
    "ex_list = ['USD', 'EUR', 'CNY']\n",
    "\n",
    "for i, j in zip(urls_list, ex_list):\n",
    "    response = requests.get(i).json()[-1]\n",
    "    print(f\"Курс {j} на {response['data'][:-9]} к рублю - {response['curs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe36b64-3896-48ed-8b33-be65230fda4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.726\n"
     ]
    }
   ],
   "source": [
    "# складываем значения элементов из первой колонки таблицы\n",
    "url = 'https://parsinger.ru/table/2/index.html'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "first_colomn = [float(column.find_all('td')[0].text) for column in soup.find_all('tr')[1:]]\n",
    "summa = sum(first_colomn)\n",
    "print(summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3595d2-0b07-4e0d-90dc-5d204cd59b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521465.6860000016\n"
     ]
    }
   ],
   "source": [
    "# в таблице в каждой строчке есть 1 оранжевая ячейка и 1 синяя (она всегда последняя), требуется перемножить значения и суммировать\n",
    "url = 'https://parsinger.ru/table/5/index.html'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "orange_list = [[float(row.find(class_ = 'orange').text), int(row.find_all('td')[-1].text)] for row in soup.find_all('tr')[1:]]\n",
    "summa = sum([elem[0]*elem[1] for elem in orange_list])\n",
    "print(summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53e5ee-210d-4368-8608-5e5dec039528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбираем машину по критериям\n",
    "url = 'https://parsinger.ru/4.8/6/index.html'\n",
    "import requests, json\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "#columns_names = [name.text for name in soup.find_all('th')]\n",
    "indices = [0, 1, 4, 7]\n",
    "columns_names = [soup.find_all('th')[i].text for i in indices]\n",
    "filtered_cars = []\n",
    "rows = soup.find_all('tr')[1:]\n",
    "for row in rows:\n",
    "    row_data =  dict(zip(columns_names, (row.find_all('td')[j].text for j in indices)))\n",
    "    if row_data['Тип двигателя'] == 'Бензиновый' and int(row_data['Стоимость авто']) <= 4000000 and int(row_data['Год выпуска']) >= 2005:\n",
    "        filtered_cars.append(row_data)\n",
    "for car in filtered_cars:\n",
    "    car[\"Стоимость авто\"] = int(car[\"Стоимость авто\"])\n",
    "    car['Год выпуска'] = int(car['Год выпуска'])\n",
    "filtered_cars.sort(key=lambda x: x[\"Стоимость авто\"])\n",
    "sorted_cars = json.dumps(filtered_cars, indent=4, ensure_ascii=False)\n",
    "#sorted(sorted_cars, key=lambda x: x[\"Стоимость авто\"])\n",
    "print(sorted_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00c1a548-2448-404f-8ff3-01b510a7c3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл result_stepik.csv создан\n"
     ]
    }
   ],
   "source": [
    "# собираем информацию про жесткие диски с 4 страниц\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('result_stepik.csv', 'w', encoding='utf-8-sig', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=';')\n",
    "    writer.writerow(['Наименование', 'Бренд', 'Форм-фактор', 'Ёмкость', 'Объем буферной памяти', 'Цена'])\n",
    "#url = 'https://parsinger.ru/html/index4_page_1.html'\n",
    "for page in range(1, 5):\n",
    "    url = f'https://parsinger.ru/html/index4_page_{page}.html'\n",
    "    response = requests.get(url=url)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    name = [x.text.strip() for x in soup.find_all('a', class_='name_item')]\n",
    "    description = [x.text.split('\\n') for x in soup.find_all('div', class_='description')]\n",
    "    price = [x.text for x in soup.find_all('p', class_='price')]\n",
    "    with open('result_stepik.csv', 'a', encoding='utf-8-sig', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        for item, descr, price in zip(name, description, price):\n",
    "            # Формируем строку для записи\n",
    "            flatten = item, *[x.split(':')[1].strip() for x in descr if x], price\n",
    "            writer.writerow(flatten)\n",
    "print('Файл result_stepik.csv создан')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "75ac237c-c982-4fe1-8459-6a8dc516bca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл watches_stepik.csv создан\n"
     ]
    }
   ],
   "source": [
    "import requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('watches_stepik.csv', 'w', encoding='utf-8-sig', newline='') as file:\n",
    "   writer = csv.writer(file, delimiter=';')\n",
    "   writer.writerow(['Наименование', 'Артикул', 'Бренд', 'Модель', 'Тип', 'Технология экрана',\n",
    "                    'Материал корпуса', 'Материал браслета', 'Размер', 'Сайт производителя',\n",
    "                    'Наличие', 'Цена', 'Старая цена', 'Ссылка на карточку с товаром'])\n",
    "\n",
    "# сперва в 'pagen' находим адреса 4 страниц с перечнем часов\n",
    "url = 'https://parsinger.ru/html/index1_page_1.html'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "sites = ['https://parsinger.ru/html/' + big_page.get('href') for big_page in soup.find('div', class_='pagen').find_all('a')]\n",
    "\n",
    "# теперь с этих 4 страниц собираем адреса персональных страниц каждых часов\n",
    "all_pages = []\n",
    "for page in sites:\n",
    "    response = requests.get(page)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    current_page = [i.find('a').get('href') for i in soup.find_all('div', class_ = 'img_box')]\n",
    "    all_pages.extend(current_page)\n",
    "\n",
    "# теперь со всех персональных страниц собираем всю нужную информацию\n",
    "for page1 in all_pages:\n",
    "    site1 = 'https://parsinger.ru/html/' + page1\n",
    "    response = requests.get(site1)\n",
    "    html_content = response.content\n",
    "    soup1 = BeautifulSoup(html_content, 'html.parser')\n",
    "    name = [soup1.find(id = 'p_header').text, soup1.find('p', class_ = 'article').text.split(':')[1].strip()]\n",
    "    description = [x.text.split(':')[1].strip() for x in soup1.find_all('li')]\n",
    "    last = [soup1.find(id = 'in_stock').text.split(':')[1].strip(), soup1.find('span', id = 'price').text, soup1.find('span', id = 'old_price').text]\n",
    "    flatten = *name, *description, *last, site1\n",
    "    # print(flatten)\n",
    "    with open('watches_stepik.csv', 'a', encoding='utf-8-sig', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow(flatten)\n",
    "print('Файл watches_stepik.csv создан') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b81f9f80-c706-4b86-8705-a7aa203f7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл hdd.json создан\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = 'https://parsinger.ru/html/index4_page_1.html'\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "sites = ['https://parsinger.ru/html/' + big_page.get('href') for big_page in soup.find('div', class_='pagen').find_all('a')]\n",
    "\n",
    "result_json = []\n",
    "for page in sites:\n",
    "    response = requests.get(page)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    name = [x.text.strip() for x in soup.find_all('a', class_='name_item')]\n",
    "    description = [x.text.strip().split('\\n') for x in soup.find_all('div', class_='description')]\n",
    "    price = [x.text for x in soup.find_all('p', class_='price')]\n",
    "    for list_item, price_item, name in zip(description, price, name):\n",
    "        result_json.append({\n",
    "            'Наименование': name,\n",
    "            'Бренд': [x.split(':')[1].strip() for x in list_item][0],\n",
    "            'Форм-фактор': [x.split(':')[1].strip() for x in list_item][1],\n",
    "            'Ёмкость': [x.split(':')[1].strip() for x in list_item][2],\n",
    "            'Объем буферной памяти': [x.split(':')[1].strip() for x in list_item][3],\n",
    "            'Цена': price_item\n",
    "        })\n",
    "\n",
    "with open('hdd.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(result_json, file, indent=4, ensure_ascii=False)\n",
    "print('Файл hdd.json создан')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bd1a6dae-3c93-4fca-a911-fa0b6166d947",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'telethon'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtelethon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TelegramClient, events, sync, connection\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'telethon'"
     ]
    }
   ],
   "source": [
    "from telethon import TelegramClient, events, sync, connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070abe8-9206-424c-abe9-1bc8a3688532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
